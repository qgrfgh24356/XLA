# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C9bSJVa1mCZR9m0OfBCafNGESL2kN3nK
"""

!pip -q install kaggle opencv-python scikit-image scikit-learn tqdm joblib

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!mkdir -p data
!kaggle datasets download -d shivamvyasiitm/georgia-tech-data -p data --unzip

import os
from pathlib import Path
import cv2
import numpy as np
from tqdm import tqdm
from skimage.feature import hog

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import joblib

RANDOM_STATE = 42
IMG_SIZE = (128, 128)
DATA_DIR = Path("data")

HOG_PARAMS = dict(
    orientations=9,
    pixels_per_cell=(8, 8),
    cells_per_block=(2, 2),
    block_norm="L2-Hys"
)

HAAR_PATH = cv2.data.haarcascades + "haarcascade_frontalface_default.xml"

def find_dataset_root(data_dir: Path) -> Path:
    candidates = [p for p in data_dir.rglob("*") if p.is_dir()]
    best = data_dir
    best_score = -1
    for c in candidates:
        subdirs = [x for x in c.iterdir() if x.is_dir()]
        score = 0
        for s in subdirs:
            if any(s.glob("*.jpg")) or any(s.glob("*.png")) or any(s.glob("*.jpeg")):
                score += 1
        if score > best_score:
            best_score = score
            best = c
    return best

def list_images_and_labels(root: Path):
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}
    X_paths, y = [], []
    for class_dir in sorted([p for p in root.iterdir() if p.is_dir()]):
        imgs = [p for p in class_dir.rglob("*") if p.suffix.lower() in exts]
        for img_path in imgs:
            X_paths.append(str(img_path))
            y.append(class_dir.name)
    return X_paths, y

def detect_and_crop_face(img_bgr, face_cascade):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)
    if len(faces) == 0:
        return img_bgr
    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])
    return img_bgr[y:y+h, x:x+w]

def preprocess_to_hog(img_path: str, face_cascade):
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"Cannot read: {img_path}")
    face = detect_and_crop_face(img, face_cascade)
    face = cv2.resize(face, IMG_SIZE, interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
    feat = hog(gray, **HOG_PARAMS).astype(np.float32)
    return feat

# 1) Load dataset
dataset_root = find_dataset_root(DATA_DIR)
print("Dataset root:", dataset_root)

X_paths, y = list_images_and_labels(dataset_root)
print("Total images:", len(X_paths), "| Total classes:", len(set(y)))

le = LabelEncoder()
y_enc = le.fit_transform(y)

# 2) Split 80/20 (stratify)
X_train_paths, X_val_paths, y_train, y_val = train_test_split(
    X_paths, y_enc, test_size=0.2, random_state=RANDOM_STATE, stratify=y_enc
)

# 3) Haar cascade
face_cascade = cv2.CascadeClassifier(HAAR_PATH)
assert not face_cascade.empty(), "Cannot load Haar cascade"

# 4) Extract HOG
print("Extract train HOG...")
X_train = np.vstack([preprocess_to_hog(p, face_cascade) for p in tqdm(X_train_paths)])
print("Extract val HOG...")
X_val = np.vstack([preprocess_to_hog(p, face_cascade) for p in tqdm(X_val_paths)])

# 5) Train model (Scaler + LinearSVC)
clf = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(C=1.0, random_state=RANDOM_STATE, class_weight="balanced"))
])

print("Training SVM...")
clf.fit(X_train, y_train)

# 6) Evaluate 4 metrics
y_pred = clf.predict(X_val)

acc  = accuracy_score(y_val, y_pred)
prec = precision_score(y_val, y_pred, average="macro", zero_division=0)
rec  = recall_score(y_val, y_pred, average="macro", zero_division=0)
f1   = f1_score(y_val, y_pred, average="macro", zero_division=0)

print("\n===== VAL (20%) METRICS =====")
print("Accuracy         :", round(acc, 4))
print("Precision (macro):", round(prec, 4))
print("Recall (macro)   :", round(rec, 4))
print("F1 (macro)       :", round(f1, 4))

print("\nConfusion matrix:\n", confusion_matrix(y_val, y_pred))
print("\nClassification report:\n", classification_report(y_val, y_pred, target_names=le.classes_, zero_division=0))

# 7) Save
Path("models").mkdir(exist_ok=True)
joblib.dump(clf, "models/hog_svm_face_recog.joblib")
joblib.dump(le, "models/label_encoder.joblib")
print("\nSaved to models/")
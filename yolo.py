# -*- coding: utf-8 -*-
""".ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HnYdwJHwLlGopRdzNhy-QE7Tr7pgouxH
"""

!pip -q install ultralytics opencv-python matplotlib pandas tqdm scikit-learn kaggle

!mkdir -p /content/face_project/models

# YOLOv8n-Face (PyTorch .pt) t·ª´ GitHub Releases (lindevs)
!wget -O /content/face_project/models/yolov8n-face.pt \
  https://github.com/lindevs/yolov8-face/releases/latest/download/yolov8n-face-lindevs.pt

!ls -lah /content/face_project/models

from ultralytics import YOLO
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import matplotlib.pyplot as plt
import os, glob, zipfile, random
import json
import pickle
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    classification_report,
    confusion_matrix
)

YOLO_FACE_WEIGHTS = "/content/face_project/models/yolov8n-face.pt"
assert os.path.exists(YOLO_FACE_WEIGHTS), f"Kh√¥ng th·∫•y weight: {YOLO_FACE_WEIGHTS}"
print("OK weight:", YOLO_FACE_WEIGHTS, "size =", os.path.getsize(YOLO_FACE_WEIGHTS)/1024/1024, "MB")

!pip -q uninstall -y kaggle
!pip -q install -U "kaggle>=1.8.0"
!kaggle -v

!rm -rf /root/.config/kaggle /root/.kaggle

!pip -q install deepface
from deepface import DeepFace

from google.colab import userdata
os.environ["KAGGLE_API_TOKEN"] = userdata.get("KAGGLE_API_TOKEN")
assert os.environ["KAGGLE_API_TOKEN"] is not None

!mkdir -p /content/data
!kaggle datasets download -d shivamvyasiitm/georgia-tech-data -p /content/data --unzip
!ls -lah /content/data

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

# Root project
PROJ = Path("/content/face_project")
PROJ.mkdir(parents=True, exist_ok=True)

# Data folders
DATA = PROJ / "data"
SPLITS = DATA / "splits"           # file train/test csv
MAPS = DATA / "maps"               # id-name map
DETS_RAW = DATA / "detections_raw"   # ·∫£nh g·ªëc v·∫Ω bbox
ROIS_RAW = DATA / "rois_raw"         # ROI crop ch∆∞a preprocess
LOGS = DATA / "yolo_logs"           # log l·ªói
ROIS_FINAL = DATA / "rois_final"   # ti·ªÅn x·ª≠ l√Ω xong

# Models & outputs
MODELS = PROJ / "models"           # yolov8 face weights, svm/knn model...
EMB = PROJ / "embeddings"          # embeddings npy/csv
OUT = PROJ / "outputs"             # k·∫øt qu·∫£ t·ªïng h·ª£p

for p in [DETS_RAW,ROIS_RAW,LOGS,ROIS_FINAL, SPLITS, MAPS, MODELS, EMB, OUT,]:
    p.mkdir(parents=True, exist_ok=True)

print("‚úÖ Project created at:", PROJ)
print("DETS_RAW:", DETS_RAW)
print("ROIS_RAW:", ROIS_RAW)
print("LOGS:", LOGS)
print("ROIS_FINAL:", ROIS_FINAL)

# =========================
# CELL 3 ‚Äî Download/Locate dataset + Build ID/Name + Split train/test CSV
# =========================

# ---- Paths theo folder b·∫°n ƒëang c√≥ ----
PROJ = Path("/content/face_project")
assert PROJ.exists(), "‚ùå Kh√¥ng th·∫•y /content/face_project"

DATA_PROJ = PROJ / "data"
MAPS   = DATA_PROJ / "maps"
SPLITS = DATA_PROJ / "splits"
MAPS.mkdir(parents=True, exist_ok=True)
SPLITS.mkdir(parents=True, exist_ok=True)

# Dataset root theo ·∫£nh b·∫°n g·ª≠i
RAW = Path("/content/data/gt_db")
RAW.mkdir(parents=True, exist_ok=True)

# ---- Helper: check dataset already exists ----
def list_image_files(root: Path):
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".pgm"}
    return [p for p in root.rglob("*") if p.is_file() and p.suffix.lower() in exts]

imgs_now = list_image_files(RAW)
print("RAW dataset folder:", RAW)
print("Images currently in RAW:", len(imgs_now))

# ---- N·∫øu ch∆∞a c√≥ ·∫£nh => download Kaggle v√† unzip v√†o RAW ----
if len(imgs_now) == 0:
    # Kaggle auth
    assert os.path.exists("/content/kaggle.json"), "‚ùå Ch∆∞a th·∫•y /content/kaggle.json. Upload kaggle.json l√™n Colab tr∆∞·ªõc!"
    os.makedirs("/root/.kaggle", exist_ok=True)
    !cp /content/kaggle.json /root/.kaggle/
    !chmod 600 /root/.kaggle/kaggle.json

    # Download zip
    !kaggle datasets download -d shivamvyasiitm/georgia-tech-data -p /content --force

    # Unzip into RAW
    zip_path = sorted(glob.glob("/content/*.zip"))[-1]
    with zipfile.ZipFile(zip_path, "r") as z:
        z.extractall(RAW)

    imgs_now = list_image_files(RAW)
    print("‚úÖ Downloaded & extracted. Images in RAW:", len(imgs_now))

# ---- Build person folders (m·ªói ng∆∞·ªùi 1 folder) ----
# Group by parent folder
parent_to_imgs = {}
for p in imgs_now:
    parent_to_imgs.setdefault(p.parent, []).append(p)

# L·ªçc folder c√≥ ƒë·ªß ·∫£nh (>=5) ƒë·ªÉ lo·∫°i r√°c
person_dirs = [d for d, imgs in parent_to_imgs.items() if len(imgs) >= 5]
person_dirs = sorted(person_dirs, key=lambda x: x.name)

N = len(person_dirs)
print("‚úÖ Candidate person dirs:", N)
print("Example person dirs:", person_dirs[:3])

# ---- Create ID + Name (50 ng∆∞·ªùi => Person_01..Person_50) ----
# N·∫øu N != 50 v·∫´n ch·∫°y ƒë∆∞·ª£c, nh∆∞ng b·∫°n y√™u c·∫ßu dataset 50 ng∆∞·ªùi -> th∆∞·ªùng N=50
dir_to_id = {str(d): i for i, d in enumerate(person_dirs)}
id_to_name = {i: f"Person_{i+1:02d}" for i in range(N)}

map_df = pd.DataFrame({
    "id": list(id_to_name.keys()),
    "name": list(id_to_name.values()),
    "folder": [person_dirs[i].name for i in range(N)]
})
map_csv = MAPS / "id_name_map.csv"
map_df.to_csv(map_csv, index=False, encoding="utf-8-sig")
print("‚úÖ Saved ID/Name map:", map_csv)

# ---- Split train/test (3A: test trong dataset) ----
TRAIN_RATIO = 0.8
rows_train, rows_test = [], []

for d in person_dirs:
    imgs = sorted(parent_to_imgs[d])
    random.shuffle(imgs)

    n_train = max(1, int(len(imgs) * TRAIN_RATIO))
    train_imgs = imgs[:n_train]
    test_imgs  = imgs[n_train:] if (len(imgs) - n_train) >= 1 else imgs[-1:]

    pid = dir_to_id[str(d)]
    pname = id_to_name[pid]

    for p in train_imgs:
        rows_train.append({"path": str(p), "id": pid, "name": pname})
    for p in test_imgs:
        rows_test.append({"path": str(p), "id": pid, "name": pname})

train_df = pd.DataFrame(rows_train)
test_df  = pd.DataFrame(rows_test)

train_csv = SPLITS / "train.csv"
test_csv  = SPLITS / "test.csv"
train_df.to_csv(train_csv, index=False, encoding="utf-8-sig")
test_df.to_csv(test_csv, index=False, encoding="utf-8-sig")

print("‚úÖ Train CSV:", train_csv, "| samples:", len(train_df))
print("‚úÖ Test  CSV:", test_csv,  "| samples:", len(test_df))

display(train_df.head(10))

# =========================
# CELL 4 ‚Äî YOLO detect ALL RAW images -> save bbox + save raw ROI + show paired samples
# =========================

# ---- paths ----
PROJ = Path("/content/face_project")
DATA_PROJ = PROJ / "data"
SPLITS = DATA_PROJ / "splits"

RAW = Path("/content/data/gt_db")
MODELS = PROJ / "models"
YOLO_FACE_WEIGHTS = MODELS / "yolov8n-face.pt"
assert YOLO_FACE_WEIGHTS.exists(), "‚ùå Thi·∫øu weights: /content/face_project/models/yolov8n-face.pt"

yolo = YOLO(str(YOLO_FACE_WEIGHTS))

def ensure_parent(p: Path):
    p.parent.mkdir(parents=True, exist_ok=True)

def draw_bbox(img_bgr, x1,y1,x2,y2, text="face"):
    out = img_bgr.copy()
    cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)
    cv2.putText(out, text, (x1, max(0, y1-10)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
    return out

def show_images_grid(img_paths, title, cols=3, figsize=(12, 8)):
    if len(img_paths) == 0:
        print("No images to show for:", title)
        return
    rows = int(np.ceil(len(img_paths) / cols))
    plt.figure(figsize=figsize)
    for i, p in enumerate(img_paths):
        img = cv2.imread(str(p))
        if img is None:
            continue
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.subplot(rows, cols, i+1)
        plt.imshow(img_rgb)
        plt.axis("off")
        plt.title(Path(p).name, fontsize=9)
    plt.suptitle(title, fontsize=14)
    plt.tight_layout()
    plt.show()

def detect_one(raw_img_path: str, conf=0.25):
    """
    Return: (ok, det_path, roi_path, bbox_xyxy, err)
    """
    p = Path(raw_img_path)
    img = cv2.imread(str(p))
    if img is None:
        return False, None, None, None, "read_fail"

    results = yolo.predict(img, conf=conf, verbose=False)
    r = results[0]
    boxes = r.boxes
    if boxes is None or len(boxes) == 0:
        return False, None, None, None, "no_face"

    xyxy = boxes.xyxy.cpu().numpy()
    areas = (xyxy[:,2]-xyxy[:,0])*(xyxy[:,3]-xyxy[:,1])
    idx = int(np.argmax(areas))
    x1,y1,x2,y2 = xyxy[idx].astype(int)

    # clamp bbox
    H, W = img.shape[:2]
    x1 = max(0, min(W-1, x1))
    x2 = max(0, min(W,   x2))
    y1 = max(0, min(H-1, y1))
    y2 = max(0, min(H,   y2))
    if x2 <= x1 or y2 <= y1:
        return False, None, None, None, "bad_bbox"

    # relative path theo RAW (s01/09.jpg)
    rel = p.relative_to(RAW)  # s01/09.jpg

    # save raw detection image (bbox on raw)
    det_img = draw_bbox(img, x1,y1,x2,y2, text="face")
    det_path = (DETS_RAW / rel).with_suffix(".png")
    ensure_parent(det_path)
    cv2.imwrite(str(det_path), det_img)

    # save raw ROI crop
    roi = img[y1:y2, x1:x2]
    roi_path = (ROIS_RAW / rel.parent / f"{rel.stem}_roi_raw.png")
    ensure_parent(roi_path)
    cv2.imwrite(str(roi_path), roi)

    return True, det_path, roi_path, (x1,y1,x2,y2), None

# ---- load all paths ----
train_df = pd.read_csv(SPLITS / "train.csv").assign(split="train")
test_df  = pd.read_csv(SPLITS / "test.csv").assign(split="test")
all_df = pd.concat([train_df, test_df], ignore_index=True)

print("Total images to process:", len(all_df))

failed_rows = []
ok_count = 0

# L∆∞u "c·∫∑p" det/roi theo KEY l√† rel path (s01/09.jpg)
pairs = []   # list of dict: {"key":..., "det":..., "roi":..., "raw":...}

for _, row in tqdm(all_df.iterrows(), total=len(all_df), desc="YOLO detect ALL"):
    ok, det_path, roi_path, bbox, err = detect_one(row["path"], conf=0.25)
    if ok:
        ok_count += 1
        key = str(Path(row["path"]).relative_to(RAW))  # "s01/09.jpg"
        pairs.append({"key": key, "raw": row["path"], "det": det_path, "roi": roi_path})
    else:
        failed_rows.append({
            "path": row["path"],
            "split": row["split"],
            "id": row["id"],
            "name": row["name"],
            "error": err
        })

print(f"‚úÖ Done. Success: {ok_count}/{len(all_df)} | Failed: {len(failed_rows)}")

failed_csv = LOGS / "yolo_failed.csv"
pd.DataFrame(failed_rows).to_csv(failed_csv, index=False, encoding="utf-8-sig")
print("Failed list saved to:", failed_csv)

print("üëâ Output folders:")
print("   DETS_RAW:", DETS_RAW)
print("   ROIS_RAW:", ROIS_RAW)

# ---- Show PAIRED samples (c√πng khu√¥n m·∫∑t) ----
random.seed(42)
K = 6
pairs_sample = random.sample(pairs, k=min(K, len(pairs)))

det_sample = [x["det"] for x in pairs_sample]
roi_sample = [x["roi"] for x in pairs_sample]

print("\n=== SHOW SAMPLE DETECTIONS (bbox on RAW) [PAIRED] ===")
show_images_grid(det_sample, title="YOLO detections on RAW (paired sample)", cols=3, figsize=(12, 7))

print("\n=== SHOW SAMPLE ROI CROPS (raw) [PAIRED] ===")
show_images_grid(roi_sample, title="Cropped ROIs (raw) (paired sample)", cols=3, figsize=(12, 7))
# ---- Save the SAME sample shown in Cell 4 so Cell 5 can reuse ----
import pandas as pd

sample_pairs_csv = LOGS / "sample_pairs.csv"
pd.DataFrame({
    "key": [x["key"] for x in pairs_sample],          # s01/09.jpg
    "raw": [x["raw"] for x in pairs_sample],          # raw path
    "det": [str(x["det"]) for x in pairs_sample],     # det image saved
    "roi": [str(x["roi"]) for x in pairs_sample],     # roi raw saved
}).to_csv(sample_pairs_csv, index=False, encoding="utf-8-sig")

print("‚úÖ Saved sample pairs for next cells:", sample_pairs_csv)

df = pd.read_csv(sample_pairs_csv)
ROI_SAMPLE_FILES = [Path(p) for p in df["roi"].tolist()]   # ch√≠nh c√°c ROI raw ƒë√£ show ·ªü cell4
DET_SAMPLE_FILES = [Path(p) for p in df["det"].tolist()]
roi_files = sorted(list(ROIS_RAW.rglob("*_roi_raw.png")))
print("Total ROI raw files:", len(roi_files))
assert len(roi_files) > 0


def show_bgr_grid(paths, title, cols=3, figsize=(12, 7)):
    rows = int(np.ceil(len(paths)/cols))
    plt.figure(figsize=figsize)
    for i, p in enumerate(paths):
        img = cv2.imread(str(p))
        if img is None:
            continue
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.subplot(rows, cols, i+1)
        plt.imshow(img_rgb)
        plt.axis("off")
        plt.title(f"{p.parent.name}/{p.stem}", fontsize=9)
    plt.suptitle(title, fontsize=14)
    plt.tight_layout()
    plt.show()

def show_gray_grid(gray_list, title, titles, cols=3, figsize=(12, 7)):
    rows = int(np.ceil(len(gray_list)/cols))
    plt.figure(figsize=figsize)
    for i, g in enumerate(gray_list):
        plt.subplot(rows, cols, i+1)
        plt.imshow(g, cmap="gray")
        plt.axis("off")
        plt.title(titles[i], fontsize=9)
    plt.suptitle(title, fontsize=14)
    plt.tight_layout()
    plt.show()

def step_gray(roi_bgr: np.ndarray) -> np.ndarray:
    return cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)

# Show raw sample
show_bgr_grid(ROI_SAMPLE_FILES, "ROI RAW (fixed sample)")

# Show gray sample
gray_samples = []
titles = []
for p in ROI_SAMPLE_FILES:
    roi = cv2.imread(str(p))
    g = step_gray(roi)
    gray_samples.append(g)
    titles.append(f"{p.parent.name}/{p.stem}")
show_gray_grid(gray_samples, "Step 1 ‚Äî GRAY (fixed sample)", titles)

# =========================
# CELL 5.2 ‚Äî Step 2: GRAY -> DENOISE (show sample only)
# =========================
def step_denoise(gray: np.ndarray) -> np.ndarray:
    # Bilateral gi·ªØ bi√™n t·ªët h∆°n Gaussian cho face texture
    return cv2.bilateralFilter(gray, d=5, sigmaColor=40, sigmaSpace=40)

den_samples = []
titles = []

for p in ROI_SAMPLE_FILES:
    roi = cv2.imread(str(p))
    g = step_gray(roi)
    den = step_denoise(g)
    den_samples.append(den)
    titles.append(f"{p.parent.name}/{p.stem}")

show_gray_grid(den_samples, "Step 2 ‚Äî DENOISE (sample)", titles)

# =========================
# CELL 5.3 ‚Äî Step 3: DENOISE -> CLAHE (show sample only)
# =========================
def step_clahe(gray: np.ndarray) -> np.ndarray:
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(gray)

clahe_samples = []
titles = []

for p in ROI_SAMPLE_FILES:
    roi = cv2.imread(str(p))
    g = step_gray(roi)
    den = step_denoise(g)
    eq = step_clahe(den)
    clahe_samples.append(eq)
    titles.append(f"{p.parent.name}/{p.stem}")

show_gray_grid(clahe_samples, "Step 3 ‚Äî CLAHE (sample)", titles)

# =========================
# CELL 5.4 ‚Äî Step 4: CLAHE -> GAMMA (show sample only)
# =========================
def step_gamma(gray: np.ndarray, gamma: float = 0.9) -> np.ndarray:
    lut = np.array([((i / 255.0) ** gamma) * 255 for i in range(256)]).astype("uint8")
    return cv2.LUT(gray, lut)

gamma_samples = []
titles = []

for p in ROI_SAMPLE_FILES:
    roi = cv2.imread(str(p))
    g = step_gray(roi)
    den = step_denoise(g)
    eq = step_clahe(den)
    gm = step_gamma(eq, gamma=0.9)
    gamma_samples.append(gm)
    titles.append(f"{p.parent.name}/{p.stem}")

show_gray_grid(gamma_samples, "Step 4 ‚Äî GAMMA (sample)", titles)

# =========================
# CELL 5.5 ‚Äî Step 5: GAMMA -> SHARPEN (show sample)
#            + RUN ALL ROI + SAVE ONLY FINAL ROI
# =========================

def step_sharpen(gray: np.ndarray, sigma: float = 1.0, amount: float = 1.2) -> np.ndarray:
    blur = cv2.GaussianBlur(gray, (0, 0), sigmaX=sigma)
    sharp = cv2.addWeighted(gray, amount, blur, 1 - amount, 0)
    return sharp

def preprocess_roi_final(roi_bgr: np.ndarray) -> np.ndarray:
    g = step_gray(roi_bgr)
    den = step_denoise(g)
    eq = step_clahe(den)
    gm = step_gamma(eq, gamma=0.9)
    final = step_sharpen(gm, sigma=1.0, amount=1.2)
    return final

def ensure_parent(p: Path):
    p.parent.mkdir(parents=True, exist_ok=True)

# --- Show sample final (no saving steps) ---
final_samples = []
titles = []
for p in ROI_SAMPLE_FILES:
    roi = cv2.imread(str(p))
    final = preprocess_roi_final(roi)
    final_samples.append(final)
    titles.append(f"{p.parent.name}/{p.stem}")

show_gray_grid(final_samples, "Step 5 ‚Äî SHARPEN (FINAL) (sample)", titles)
# --- RUN ALL + SAVE ONLY FINAL ---
ok, fail = 0, 0
for rp in tqdm(roi_files, desc="Save FINAL ROI for ALL"):
    roi = cv2.imread(str(rp))
    if roi is None:
        fail += 1
        continue

    final = preprocess_roi_final(roi)

    # gi·ªØ c·∫•u tr√∫c: s01/09_roi_raw.png -> s01/09_roi_final.png
    rel = rp.relative_to(ROIS_RAW)
    out_name = rel.name.replace("_roi_raw", "_roi_final")
    out_path = (ROIS_FINAL / rel.parent / out_name).with_suffix(".png")
    ensure_parent(out_path)
    cv2.imwrite(str(out_path), final)
    ok += 1

print(f"‚úÖ DONE. Saved final ROI: {ok} | Failed reads: {fail}")
print("Final ROI folder:", ROIS_FINAL)

# --- Show a few saved finals (quick check) ---
saved_final_files = sorted(list(ROIS_FINAL.rglob("*_roi_final.png")))
random.seed(42)
check_files = random.sample(saved_final_files, k=min(6, len(saved_final_files)))

# Show saved final images
imgs = []
titles = []
for p in check_files:
    g = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)
    imgs.append(g)
    titles.append(f"{p.parent.name}/{p.stem}")
show_gray_grid(imgs, "Saved FINAL ROI (sample from disk)", titles)

# =========================
# CELL 6 ‚Äî Facenet512 embeddings (ALL) from rois_final -> save .npy + meta.csv
#         (FIX: use DeepFace.represent, no model=, no .predict)
# =========================
# ---- Paths ----
PROJ = Path("/content/face_project")
DATA_PROJ = PROJ / "data"
SPLITS = DATA_PROJ / "splits"
ROIS_FINAL = DATA_PROJ / "rois_final"     # from Step 5.5
RAW = Path("/content/data/gt_db")

EMB_DIR = PROJ / "embeddings"
EMB_DIR.mkdir(parents=True, exist_ok=True)

train_df = pd.read_csv(SPLITS / "train.csv").assign(split="train")
test_df  = pd.read_csv(SPLITS / "test.csv").assign(split="test")
all_df = pd.concat([train_df, test_df], ignore_index=True)

assert ROIS_FINAL.exists(), "‚ùå Kh√¥ng th·∫•y rois_final. B·∫°n ph·∫£i ch·∫°y Step 5.5 tr∆∞·ªõc."
print("Total rows (train+test):", len(all_df))

MODEL_NAME = "Facenet512"
FACE_SIZE = (160, 160)  # (W,H)

def roi_final_path_from_raw(raw_path: str) -> Path:
    """
    raw: /content/data/gt_db/s01/09.jpg
    roi_final: /content/face_project/data/rois_final/s01/09_roi_final.png
    """
    p = Path(raw_path)
    rel = p.relative_to(RAW)
    return (ROIS_FINAL / rel.parent / f"{rel.stem}_roi_final.png")

def gray_to_rgb3(gray: np.ndarray) -> np.ndarray:
    """
    gray (H,W) -> resize -> stack 3ch -> RGB
    """
    g = cv2.resize(gray, FACE_SIZE, interpolation=cv2.INTER_AREA)
    bgr3 = cv2.merge([g, g, g])                 # (H,W,3) BGR
    rgb3 = cv2.cvtColor(bgr3, cv2.COLOR_BGR2RGB)
    return rgb3

def get_facenet512_embedding(rgb_img: np.ndarray) -> np.ndarray:
    """
    rgb_img: (160,160,3) uint8 RGB
    -> DeepFace.represent -> (512,) float32 + L2 norm
    """
    rep = DeepFace.represent(
        img_path=rgb_img,
        model_name=MODEL_NAME,
        detector_backend="skip",
        enforce_detection=False,
        normalization="base"
    )
    emb = np.array(rep[0]["embedding"], dtype=np.float32)
    emb = emb / (np.linalg.norm(emb) + 1e-12)
    return emb

# ---- Build embeddings ----
X_train, y_train = [], []
X_test, y_test = [], []

meta_rows = []
missing_roi = 0
read_fail = 0
ok = 0

for _, row in tqdm(all_df.iterrows(), total=len(all_df), desc="Facenet512 Embeddings ALL"):
    raw_path = row["path"]
    pid = int(row["id"])
    name = row["name"]
    split = row["split"]

    roi_path = roi_final_path_from_raw(raw_path)
    if not roi_path.exists():
        missing_roi += 1
        meta_rows.append({
            "raw_path": raw_path, "roi_final": str(roi_path),
            "id": pid, "name": name, "split": split, "status": "missing_roi"
        })
        continue

    gray = cv2.imread(str(roi_path), cv2.IMREAD_GRAYSCALE)
    if gray is None:
        read_fail += 1
        meta_rows.append({
            "raw_path": raw_path, "roi_final": str(roi_path),
            "id": pid, "name": name, "split": split, "status": "read_fail"
        })
        continue

    rgb = gray_to_rgb3(gray)
    emb = get_facenet512_embedding(rgb)

    if split == "train":
        X_train.append(emb); y_train.append(pid)
    else:
        X_test.append(emb); y_test.append(pid)

    meta_rows.append({
        "raw_path": raw_path, "roi_final": str(roi_path),
        "id": pid, "name": name, "split": split, "status": "ok"
    })
    ok += 1

X_train = np.vstack(X_train) if len(X_train) else np.empty((0, 512), dtype=np.float32)
y_train = np.array(y_train, dtype=np.int32)
X_test  = np.vstack(X_test)  if len(X_test)  else np.empty((0, 512), dtype=np.float32)
y_test  = np.array(y_test, dtype=np.int32)

print("\n‚úÖ Embedding done.")
print("OK:", ok, "| Missing ROI:", missing_roi, "| Read fail:", read_fail)
print("X_train:", X_train.shape, "y_train:", y_train.shape)
print("X_test :", X_test.shape,  "y_test :", y_test.shape)

# ---- Save npy ----
np.save(EMB_DIR / "X_train.npy", X_train)
np.save(EMB_DIR / "y_train.npy", y_train)
np.save(EMB_DIR / "X_test.npy", X_test)
np.save(EMB_DIR / "y_test.npy", y_test)

# ---- Save meta ----
meta_df = pd.DataFrame(meta_rows)
meta_csv = EMB_DIR / "embeddings_meta.csv"
meta_df.to_csv(meta_csv, index=False, encoding="utf-8-sig")

print("\n‚úÖ Saved:")
print(" -", EMB_DIR / "X_train.npy")
print(" -", EMB_DIR / "y_train.npy")
print(" -", EMB_DIR / "X_test.npy")
print(" -", EMB_DIR / "y_test.npy")
print(" -", meta_csv)

# ---- Sanity check ----
if X_train.shape[0] > 0:
    norms = np.linalg.norm(X_train[:5], axis=1)
    print("\nSanity check (first 5 train embedding L2 norms) ~ should be 1.0:", norms)
    print("Embedding dim:", X_train.shape[1])

# =========================
# CELL 7 ‚Äî Train SVM  -> Accuracy, Precision, Recall, F1 (macro/weighted) -> Save
# =========================
# ---- Paths ----
PROJ = Path("/content/face_project")
EMB_DIR = PROJ / "embeddings"
MODELS = PROJ / "models"
OUT = PROJ / "outputs"
MODELS.mkdir(parents=True, exist_ok=True)
OUT.mkdir(parents=True, exist_ok=True)

# ---- Load embeddings ----
X_train = np.load(EMB_DIR / "X_train.npy")
y_train = np.load(EMB_DIR / "y_train.npy")
X_test  = np.load(EMB_DIR / "X_test.npy")
y_test  = np.load(EMB_DIR / "y_test.npy")

print("X_train:", X_train.shape, "y_train:", y_train.shape)
print("X_test :", X_test.shape,  "y_test :", y_test.shape)
assert X_train.shape[0] > 0 and X_test.shape[0] > 0, "‚ùå Embeddings r·ªóng. Ki·ªÉm tra Cell 6."

def summary_metrics(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)

    p_macro, r_macro, f_macro, _ = precision_recall_fscore_support(
        y_true, y_pred, average="macro", zero_division=0
    )
    p_weight, r_weight, f_weight, _ = precision_recall_fscore_support(
        y_true, y_pred, average="weighted", zero_division=0
    )
    return {
        "accuracy": float(acc),
        "precision_macro": float(p_macro),
        "recall_macro": float(r_macro),
        "f1_macro": float(f_macro),
        "precision_weighted": float(p_weight),
        "recall_weighted": float(r_weight),
        "f1_weighted": float(f_weight),
    }

# =========================
# 1) Train SVM
# =========================
svm = SVC(kernel="rbf", C=10, gamma="scale", probability=True, random_state=42)
svm.fit(X_train, y_train)

pred_svm = svm.predict(X_test)
svm_metrics = summary_metrics(y_test, pred_svm)

print("\n================ SVM RESULTS ================")
print("Accuracy:", svm_metrics["accuracy"])
print("Precision (macro):", svm_metrics["precision_macro"])
print("Recall    (macro):", svm_metrics["recall_macro"])
print("F1        (macro):", svm_metrics["f1_macro"])
print("\n--- Classification report (SVM) ---")
print(classification_report(y_test, pred_svm, digits=4, zero_division=0))


# =========================
# Save models
# =========================
svm_path = MODELS / "svm_facenet512.pkl"

with open(svm_path, "wb") as f:
    pickle.dump(svm, f)

print("\n‚úÖ Saved models:")
print(" -", svm_path)

# =========================
# Save metrics JSON
# =========================
metrics = {
    "svm": {
        **svm_metrics,
        "params": {"kernel": "rbf", "C": 10, "gamma": "scale"},
        "confusion_matrix_shape": list(confusion_matrix(y_test, pred_svm).shape),
    },
    "data": {
        "train_samples": int(X_train.shape[0]),
        "test_samples": int(X_test.shape[0]),
        "embedding_dim": int(X_train.shape[1]),
        "num_classes_train": int(len(np.unique(y_train))),
        "num_classes_test": int(len(np.unique(y_test))),
    }
}

metrics_path = OUT / "metrics_facenet512.json"
with open(metrics_path, "w", encoding="utf-8") as f:
    json.dump(metrics, f, ensure_ascii=False, indent=2)

print("‚úÖ Saved metrics:", metrics_path)

# =========================
# CELL 8 ‚Äî FINAL OUTPUT: raw test image -> YOLO bbox -> ROI preprocess -> FaceNet512 -> SVM -> draw ID+Name
# =========================
# ---- Paths ----
PROJ = Path("/content/face_project")
DATA_PROJ = PROJ / "data"
SPLITS = DATA_PROJ / "splits"
MAPS = DATA_PROJ / "maps"
OUT = PROJ / "outputs"
MODELS = PROJ / "models"
RAW = Path("/content/data/gt_db")

OUT.mkdir(parents=True, exist_ok=True)

# ---- Load split + map ----
test_df = pd.read_csv(SPLITS / "test.csv")
map_df = pd.read_csv(MAPS / "id_name_map.csv")
id_to_name = dict(zip(map_df["id"], map_df["name"]))

# ---- Load YOLO face ----
YOLO_FACE_WEIGHTS = MODELS / "yolov8n-face.pt"
assert YOLO_FACE_WEIGHTS.exists(), "‚ùå Thi·∫øu YOLO weights: /content/face_project/models/yolov8n-face.pt"
yolo = YOLO(str(YOLO_FACE_WEIGHTS))

# ---- Load classifiers ----
svm_path = MODELS / "svm_facenet512.pkl"


with open(svm_path, "rb") as f:
    svm = pickle.load(f)

# ---- Facenet config ----
MODEL_NAME = "Facenet512"
FACE_SIZE = (160, 160)  # (W,H)

# =========================
# Preprocess ROI (5 steps) - gi·ªëng Step 5.x
# =========================
def step_gray(roi_bgr: np.ndarray) -> np.ndarray:
    return cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)

def step_denoise(gray: np.ndarray) -> np.ndarray:
    return cv2.bilateralFilter(gray, d=5, sigmaColor=40, sigmaSpace=40)

def step_clahe(gray: np.ndarray) -> np.ndarray:
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(gray)

def step_gamma(gray: np.ndarray, gamma: float = 0.9) -> np.ndarray:
    lut = np.array([((i / 255.0) ** gamma) * 255 for i in range(256)]).astype("uint8")
    return cv2.LUT(gray, lut)

def step_sharpen(gray: np.ndarray, sigma: float = 1.0, amount: float = 1.2) -> np.ndarray:
    blur = cv2.GaussianBlur(gray, (0, 0), sigmaX=sigma)
    sharp = cv2.addWeighted(gray, amount, blur, 1 - amount, 0)
    return sharp

def preprocess_roi_5steps(roi_bgr: np.ndarray):
    g1 = step_gray(roi_bgr)
    g2 = step_denoise(g1)
    g3 = step_clahe(g2)
    g4 = step_gamma(g3, gamma=0.9)
    g5 = step_sharpen(g4, sigma=1.0, amount=1.2)
    steps = {"01_gray": g1, "02_denoise": g2, "03_clahe": g3, "04_gamma": g4, "05_final": g5}
    return g5, steps

def gray_to_rgb3(gray: np.ndarray) -> np.ndarray:
    g = cv2.resize(gray, FACE_SIZE, interpolation=cv2.INTER_AREA)
    bgr3 = cv2.merge([g, g, g])
    rgb3 = cv2.cvtColor(bgr3, cv2.COLOR_BGR2RGB)
    return rgb3

def facenet512_embedding_from_gray(gray_final: np.ndarray) -> np.ndarray:
    rgb = gray_to_rgb3(gray_final)
    rep = DeepFace.represent(
        img_path=rgb,
        model_name=MODEL_NAME,
        detector_backend="skip",
        enforce_detection=False,
        normalization="base"
    )
    emb = np.array(rep[0]["embedding"], dtype=np.float32)
    emb = emb / (np.linalg.norm(emb) + 1e-12)
    return emb

# =========================
# YOLO detect helper
# =========================
def detect_largest_face_bbox(img_bgr: np.ndarray, conf=0.25):
    res = yolo.predict(img_bgr, conf=conf, verbose=False)[0]
    boxes = res.boxes
    if boxes is None or len(boxes) == 0:
        return None
    xyxy = boxes.xyxy.cpu().numpy()
    areas = (xyxy[:,2]-xyxy[:,0])*(xyxy[:,3]-xyxy[:,1])
    idx = int(np.argmax(areas))
    x1,y1,x2,y2 = xyxy[idx].astype(int)
    H,W = img_bgr.shape[:2]
    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W, x2))
    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H, y2))
    if x2 <= x1 or y2 <= y1:
        return None
    return (x1,y1,x2,y2)

def draw_bbox_label(img_bgr, bbox, text):
    x1,y1,x2,y2 = bbox
    out = img_bgr.copy()
    cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)
    cv2.putText(out, text, (x1, max(0, y1-10)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)
    return out

# =========================
# RUN 1 SAMPLE TEST IMAGE
# =========================
METHOD = "svm"      # "svm"
SHOW_STEPS = True   # True ƒë·ªÉ hi·ªán 5 b∆∞·ªõc preprocessing c·ªßa ROI
CONF_YOLO = 0.25

# ch·ªçn 1 ·∫£nh test ng·∫´u nhi√™n
random.seed(42)
row = test_df.sample(1, random_state=42).iloc[0]
raw_path = row["path"]
true_id = int(row["id"])
true_name = row["name"]

img = cv2.imread(raw_path)
assert img is not None, f"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {raw_path}"

bbox = detect_largest_face_bbox(img, conf=CONF_YOLO)
if bbox is None:
    print("‚ùå YOLO kh√¥ng detect ƒë∆∞·ª£c m·∫∑t:", raw_path)
else:
    x1,y1,x2,y2 = bbox
    roi = img[y1:y2, x1:x2]

    # preprocess ROI (5 steps)
    final_gray, steps = preprocess_roi_5steps(roi)

    # optional: show steps
    if SHOW_STEPS:
        fig = plt.figure(figsize=(12, 6))
        keys = ["01_gray","02_denoise","03_clahe","04_gamma","05_final"]
        for i,k in enumerate(keys, start=1):
            plt.subplot(2,3,i)
            plt.imshow(steps[k], cmap="gray")
            plt.title(k)
            plt.axis("off")
        plt.suptitle("ROI preprocessing steps (sample)")
        plt.tight_layout()
        plt.show()

    # embedding
    emb = facenet512_embedding_from_gray(final_gray).reshape(1, -1)

    # predict
    if METHOD.lower() == "svm":
        pred_id = int(svm.predict(emb)[0])
        proba = svm.predict_proba(emb)[0]
        conf = float(np.max(proba))
        model_name = "SVM"


    pred_name = id_to_name.get(pred_id, f"Person_{pred_id+1:02d}")

    label = f"{model_name} | ID {pred_id:02d} - {pred_name} ({conf:.2f})"
    gt = f"GT: ID {true_id:02d} - {true_name}"

    out_img = draw_bbox_label(img, bbox, label)

    # show final output
    plt.figure(figsize=(8,6))
    plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.title(gt)
    plt.show()

    # save output
    save_path = OUT / f"result_{model_name.lower()}_{Path(raw_path).stem}.png"
    cv2.imwrite(str(save_path), out_img)
    print("‚úÖ Saved output:", save_path)
    print("Raw image:", raw_path)
    print("Prediction:", label)
    print("Ground truth:", gt)

# =========================
# CELL ‚Äî ROC Curve for SVM (multi-class, One-vs-Rest)
# Plot: Micro-average ROC + Macro-average ROC
# =========================
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

# 1) Get probability scores (N, C)
proba = svm.predict_proba(X_test)  # requires probability=True
classes = svm.classes_             # array of class labels seen by svm
n_classes = len(classes)

print("proba shape:", proba.shape, "| n_classes:", n_classes)

# 2) Binarize y_test into one-hot (N, C) aligned with svm.classes_
y_bin = label_binarize(y_test, classes=classes)

# Edge case: if test set misses some classes, label_binarize still creates correct shape
print("y_bin shape:", y_bin.shape)

# 3) Compute ROC for each class (optional, too many if 50)
# We'll compute micro & macro averages.

# ---- Micro-average ROC (treat all classes jointly) ----
fpr_micro, tpr_micro, _ = roc_curve(y_bin.ravel(), proba.ravel())
auc_micro = auc(fpr_micro, tpr_micro)

# ---- Macro-average ROC (average over classes) ----
# Compute per-class ROC + AUC
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    # If a class has no positive samples in test, roc_curve can error.
    # We'll skip those classes safely.
    if np.sum(y_bin[:, i]) == 0:
        continue
    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

valid_classes = sorted(roc_auc.keys())
print("Classes with positives in test:", len(valid_classes), "/", n_classes)

# Build macro-average by interpolating all valid class curves on a common FPR grid
all_fpr = np.unique(np.concatenate([fpr[i] for i in valid_classes])) if valid_classes else np.array([0.0, 1.0])

mean_tpr = np.zeros_like(all_fpr)
for i in valid_classes:
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
mean_tpr /= max(len(valid_classes), 1)

auc_macro = auc(all_fpr, mean_tpr)

# 4) Plot
plt.figure(figsize=(8, 6))

# Diagonal baseline
plt.plot([0, 1], [0, 1], linestyle="--")

# Micro and Macro ROC (no fixed colors requested)
plt.plot(fpr_micro, tpr_micro, label=f"Micro-average ROC (AUC = {auc_micro:.4f})")
plt.plot(all_fpr, mean_tpr, label=f"Macro-average ROC (AUC = {auc_macro:.4f})")

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve ‚Äî SVM (multi-class OvR)")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

print(f"\nAUC micro: {auc_micro:.4f}")
print(f"AUC macro: {auc_macro:.4f}")

# =========================
# CELL 8 ‚Äî TEST ALL IMAGES IN A FOLDER
# Run all + save outputs + show summary for K images
# Show preprocess steps ONLY for the first shown image
# =========================
from pathlib import Path
import cv2, numpy as np, pandas as pd, pickle, random
import matplotlib.pyplot as plt
from tqdm import tqdm
from ultralytics import YOLO
from deepface import DeepFace

# ---- Paths ----
PROJ = Path("/content/face_project")
DATA_PROJ = PROJ / "data"
MAPS = DATA_PROJ / "maps"
MODELS = PROJ / "models"
OUT = PROJ / "outputs"

IN_DIR = DATA_PROJ / "test_images_external"
assert IN_DIR.exists(), f"‚ùå Kh√¥ng th·∫•y folder: {IN_DIR}"

# output folder
METHOD = "svm"   # "svm" or "knn"
OUT_DIR = OUT / f"external_batch_{METHOD.lower()}"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ---- Load id->name map ----
map_df = pd.read_csv(MAPS / "id_name_map.csv")
id_to_name = dict(zip(map_df["id"], map_df["name"]))

# ---- Load YOLO ----
YOLO_FACE_WEIGHTS = MODELS / "yolov8n-face.pt"
assert YOLO_FACE_WEIGHTS.exists(), "‚ùå Thi·∫øu YOLO weights: /content/face_project/models/yolov8n-face.pt"
yolo = YOLO(str(YOLO_FACE_WEIGHTS))

# ---- Load classifiers ----
with open(MODELS / "svm_facenet512.pkl", "rb") as f:
    svm = pickle.load(f)

# ---- Settings ----
CONF_YOLO = 0.25
THRESH = 0.15      # cls_conf < THRESH => Unknown
MODEL_NAME = "Facenet512"
FACE_SIZE = (160, 160)  # (W,H)

SHOW_N = 6
SHOW_MODE = "random"    # "first" or "random"
SEED = 42
SHOW_STEPS = True
SHOW_STEPS_ONLY_FIRST = True   # ch·ªâ show 5 b∆∞·ªõc cho 1 ·∫£nh

# =========================
# Preprocess ROI (5 steps)
# =========================
def step_gray(roi_bgr): return cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)
def step_denoise(gray): return cv2.bilateralFilter(gray, d=5, sigmaColor=40, sigmaSpace=40)
def step_clahe(gray):
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(gray)
def step_gamma(gray, gamma=0.9):
    lut = np.array([((i / 255.0) ** gamma) * 255 for i in range(256)]).astype("uint8")
    return cv2.LUT(gray, lut)
def step_sharpen(gray, sigma=1.0, amount=1.2):
    blur = cv2.GaussianBlur(gray, (0, 0), sigmaX=sigma)
    return cv2.addWeighted(gray, amount, blur, 1 - amount, 0)

def preprocess_roi_5steps(roi_bgr):
    g1 = step_gray(roi_bgr)
    g2 = step_denoise(g1)
    g3 = step_clahe(g2)
    g4 = step_gamma(g3, gamma=0.9)
    g5 = step_sharpen(g4, sigma=1.0, amount=1.2)
    steps = {"01_gray": g1, "02_denoise": g2, "03_clahe": g3, "04_gamma": g4, "05_final": g5}
    return g5, steps

def gray_to_rgb3(gray):
    g = cv2.resize(gray, FACE_SIZE, interpolation=cv2.INTER_AREA)
    bgr3 = cv2.merge([g, g, g])
    rgb3 = cv2.cvtColor(bgr3, cv2.COLOR_BGR2RGB)
    return rgb3

def facenet512_embedding_from_gray(gray_final):
    rgb = gray_to_rgb3(gray_final)
    rep = DeepFace.represent(
        img_path=rgb,
        model_name=MODEL_NAME,
        detector_backend="skip",
        enforce_detection=False,
        normalization="base"
    )
    emb = np.array(rep[0]["embedding"], dtype=np.float32)
    emb = emb / (np.linalg.norm(emb) + 1e-12)
    return emb

# =========================
# YOLO detect + draw helpers
# =========================
def detect_largest_face_bbox(img_bgr, conf=0.25):
    res = yolo.predict(img_bgr, conf=conf, verbose=False)[0]
    boxes = res.boxes
    if boxes is None or len(boxes) == 0:
        return None, None
    xyxy = boxes.xyxy.cpu().numpy()
    confs = boxes.conf.cpu().numpy()
    areas = (xyxy[:,2]-xyxy[:,0])*(xyxy[:,3]-xyxy[:,1])
    idx = int(np.argmax(areas))
    x1,y1,x2,y2 = xyxy[idx].astype(int)
    yolo_conf = float(confs[idx])
    H,W = img_bgr.shape[:2]
    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W, x2))
    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H, y2))
    if x2 <= x1 or y2 <= y1:
        return None, None
    return (x1,y1,x2,y2), yolo_conf

def draw_bbox_label(img_bgr, bbox, text):
    x1,y1,x2,y2 = bbox
    out = img_bgr.copy()
    cv2.rectangle(out, (x1,y1), (x2,y2), (0,255,0), 2)
    cv2.putText(out, text, (x1, max(0, y1-10)),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
    return out

def show_steps(steps, title="ROI preprocess steps"):
    keys = ["01_gray","02_denoise","03_clahe","04_gamma","05_final"]
    plt.figure(figsize=(12,6))
    for i,k in enumerate(keys, start=1):
        plt.subplot(2,3,i)
        plt.imshow(steps[k], cmap="gray")
        plt.title(k)
        plt.axis("off")
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

# ---- Collect images ----
img_files = []
for ext in ["*.jpg","*.jpeg","*.png","*.webp"]:
    img_files += list(IN_DIR.glob(ext))
img_files = sorted(img_files)

print("Input folder:", IN_DIR)
print("Total images:", len(img_files))
assert len(img_files) > 0, "‚ùå Folder test_images_external ƒëang r·ªóng."

# choose which files to show (summary)
if SHOW_MODE == "first":
    show_files = img_files[:min(SHOW_N, len(img_files))]
else:
    random.seed(SEED)
    show_files = random.sample(img_files, k=min(SHOW_N, len(img_files)))

# choose ONE file to show steps
STEP_FILE = show_files[0] if (SHOW_STEPS and SHOW_STEPS_ONLY_FIRST and len(show_files) > 0) else None
print("STEP_FILE (show preprocess steps):", STEP_FILE.name if STEP_FILE else None)

rows = []

for p in tqdm(img_files, desc=f"External folder infer ({METHOD})"):
    img = cv2.imread(str(p))
    if img is None:
        rows.append({"file": p.name, "status": "read_fail"})
        continue

    bbox, yolo_conf = detect_largest_face_bbox(img, conf=CONF_YOLO)
    if bbox is None:
        out_path = OUT_DIR / f"{p.stem}_NOFACE.png"
        cv2.imwrite(str(out_path), img)
        rows.append({"file": p.name, "status": "no_face", "saved": str(out_path)})
        continue

    x1,y1,x2,y2 = bbox
    roi = img[y1:y2, x1:x2]

    final_gray, steps = preprocess_roi_5steps(roi)
    emb = facenet512_embedding_from_gray(final_gray).reshape(1, -1)

    if METHOD.lower() == "svm":
        pred_id = int(svm.predict(emb)[0])
        cls_conf = float(np.max(svm.predict_proba(emb)[0]))
        tag = "SVM"
    else:
        pred_id = int(knn.predict(emb)[0])
        cls_conf = float(np.max(knn.predict_proba(emb)[0]))
        tag = "KNN"

    if cls_conf < THRESH:
        pred_name = "Unknown"
        pred_id_out = -1
        label = f"{tag} | Unknown | yolo={yolo_conf:.2f} cls={cls_conf:.2f}"
    else:
        pred_name = id_to_name.get(pred_id, f"Person_{pred_id+1:02d}")
        pred_id_out = pred_id
        label = f"{tag} | ID {pred_id:02d}-{pred_name} | yolo={yolo_conf:.2f} cls={cls_conf:.2f}"

    out_img = draw_bbox_label(img, bbox, label)
    out_path = OUT_DIR / f"{p.stem}_OUT.png"
    cv2.imwrite(str(out_path), out_img)

    rows.append({
        "file": p.name,
        "status": "ok",
        "pred_id": pred_id_out,
        "pred_name": pred_name,
        "yolo_conf": yolo_conf,
        "cls_conf": cls_conf,
        "saved": str(out_path)
    })

    # ---- SHOW summary for selected files; steps only for STEP_FILE ----
    show_set = set(show_files)   # ƒë·ªÉ check nhanh
    steps_shown = False          # ch∆∞a show steps cho ·∫£nh n√†o
    # trong loop, ngay ƒëo·∫°n SHOW:
    if p in show_set:
        # ·∫£nh ƒë·∫ßu ti√™n ƒë∆∞·ª£c show -> show steps (1 l·∫ßn duy nh·∫•t)
        if SHOW_STEPS and SHOW_STEPS_ONLY_FIRST and (not steps_shown):
            show_steps(steps, title=f"Preprocess steps (FIRST SHOWN): {p.name}")
            steps_shown = True

        plt.figure(figsize=(8,6))
        plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))
        plt.axis("off")
        plt.title(f"{p.name} | {label}")
        plt.show()
res_df = pd.DataFrame(rows)
display(res_df)

csv_path = OUT_DIR / "external_folder_results.csv"
res_df.to_csv(csv_path, index=False, encoding="utf-8-sig")

print("\n‚úÖ Saved results CSV:", csv_path)
print("‚úÖ Saved output images:", OUT_DIR)
print("Shown files:", [p.name for p in show_files])

